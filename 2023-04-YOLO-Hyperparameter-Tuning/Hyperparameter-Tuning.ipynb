{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning YOLO\n",
    "\n",
    "Object detection is a computer vision task that involves identifying objects in both images and videos. \n",
    "YOLO (standing for _You Only Look Once_) is a state-of-the-art object detection model that is widely used within the computer vision field.\n",
    "It uses a Convolutional Neural Network (CNN) that takes an image as an input and predicts bouding boxes around an object and the corresponding class label.\n",
    "\n",
    "YOLOv8 is the newest of the series of YOLO models and will be used throughout this blog.\n",
    "\n",
    "When training any machine learning model, hyperparameter tuning is an essential part. \n",
    "Hyperparameters are parameters that influence the learning process during model training.\n",
    "In order to produce the best possible predictions from a model, we must find the optimal set of hyperparameters.\n",
    "\n",
    "In this blog, we will describe how to run a custom YOLOv8 model using Amazon SageMaker's resources to find the optimal hyperparameter configuration.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this blog, we will assume the following:\n",
    "- We have a set of training images and labels saved in an S3 bucket\n",
    "- We have a _train.py_ file that contains the YOLO model\n",
    "- We have a _.yaml_ file that contains the directory of training and validation and the number of classes and label names\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, to run a hyperparameter tuning job, we need to set up an Estimator. An example is shown below and more details on each input can be found [here](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html). Before we can do this, we must import all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.tuner import CategoricalParameter, ContinuousParameter\n",
    "from sagemaker.tuner import HyperparameterTuner, HyperbandStrategyConfig, StrategyConfig\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the metric definitions for the YOLO model\n",
    "\n",
    "metric_definitions=[\n",
    "    {\n",
    "        \"Name\": \"precision\",\n",
    "        \"Regex\": \"YOLO Metric metrics/precision\\\\(B\\\\): (.*)\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"recall\",\n",
    "        \"Regex\": \"YOLO Metric metrics/recall\\\\(B\\\\): (.*)\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"mAP50\",\n",
    "        \"Regex\": \"YOLO Metric metrics/mAP50\\\\(B\\\\): (.*)\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"mAP50-95\",\n",
    "        \"Regex\": \"YOLO Metric metrics/mAP50-95\\\\(B\\\\): (.*)\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"box_loss\",\n",
    "        \"Regex\": \"YOLO Metric val/box_loss: (.*)\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"cls_loss\",\n",
    "        \"Regex\": \"YOLO Metric val/cls_loss: (.*)\"\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"dfl_loss\",\n",
    "        \"Regex\": \"YOLO Metric val/dfl_loss: (.*)\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    image_uri='your/image',  # your image\n",
    "    source_dir=\"./src\",\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    framework_version=\"1.12.1\",\n",
    "    py_version=\"py38\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    hyperparameters={},\n",
    "    use_spot_instances=True,\n",
    "    input_mode='File',  # FastFile causes a issue with writing label cache\n",
    "    debugger_hook_config=False,\n",
    "    max_wait=360000+3600,\n",
    "    max_run=360000,\n",
    "    output_path='path/to/output',\n",
    "    enable_sagemaker_metrics=True,\n",
    "    metric_definitions=metric_definitions,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimator defined above, takes your _train.py_, (the `source_dir` needs to be where this file is saved) sets an instance type, uses a spot instance and has a `max_run` time of 100 hours. This means that after 100 hours Amazon SageMaker terminates the job regardless of its current status. Any hyperparameters you want to keep the same value throughout the training jobs can also be set as a constant here. Again, more details on these can be found [here](https://sagemaker.readthedocs.io/en/stable/api/training/estimators.html)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned at the start, we need a _yaml_ file to run the YOLOv8 model. This should contain the following details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .yaml file\n",
    "\n",
    "# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]\n",
    "path:  /opt/ml/input/your/s3/bucket  # dataset root dir\n",
    "train: images/train  # train images (relative to 'path')\n",
    "val: images/train  # val images (relative to 'path')\n",
    "test:  # test/images # test images (optional)\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: 'label1'\n",
    "  1: 'label2'\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _train.py_ file should be similar to the following, with the hyperparameters that you are wanting to tune added to the parser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--epochs', help='number of training epochs')\n",
    "parser.add_argument('--optimizer', help='optimizer to use')\n",
    "parser.add_argument('--lr0', help='initial learning rate')\n",
    "parser.add_argument('--lrf', help='final learning rate')\n",
    "parser.add_argument('--momentum', help='momentum')\n",
    "parser.add_argument('--weight_decay', help='optimizer weight decay')\n",
    "args = parser.parse_args()\n",
    "\n",
    "print('---------------Debug injected environment and arguments--------------------')\n",
    "print(sys.argv)\n",
    "print(os.environ)\n",
    "print('---------------End debug----------------------')\n",
    "\n",
    "model = YOLO(\"yolov8n.yaml\")\n",
    "\n",
    "model.train(data='./blaa.yaml', \n",
    "            epochs=int(args.epochs), \n",
    "            batch=64, \n",
    "            optimizer=args.optimizer, \n",
    "            lr0=float(args.lr0), \n",
    "            lrf=float(args.lrf), \n",
    "            momentum=float(args.momentum),\n",
    "            weight_decay=float(args.weight_decay)\n",
    "           )\n",
    "\n",
    "model.export()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to define the hyperparameters the ranges of the hyperparameters you want to tune. This is shown below; where each hyperparameter is either an `IntegerParameter`, `CategoricalParameter` or a `ContinuousParameter`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hyperparameter_ranges={\n",
    "    'epochs':IntegerParameter(100, 300),\n",
    "    'optimizer':CategoricalParameter(['SGD', 'Adam', 'AdamW', 'RMSProp']),\n",
    "    'lr0': ContinuousParameter(0.00001, 0.01),\n",
    "    'lrf': ContinuousParameter(0.00001, 0.01),\n",
    "    'momentum': ContinuousParameter(0.9, 0.9999),\n",
    "    'weight_decay': ContinuousParameter(0.0003, 0.00099)\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a tuner we use HyperparameterTuner which takes the following inputs:\n",
    "- Our estimator\n",
    "- The objective metric and definition (definitions set above)\n",
    "    - here we have chosen to maximise the mean average precision mAP\n",
    "- Hyperparameter ranges\n",
    "- Strategy\n",
    "    - We have set the strategy to be _Hyperband_. More details on these options [here](https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning-how-it-works.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tuner = HyperparameterTuner(estimator, \n",
    "                            objective_metric_name=\"mAP50-95\", \n",
    "                            metric_definitions=metric_definitions, \n",
    "                            hyperparameter_ranges= hyperparameter_ranges, \n",
    "                            strategy='Hyperband',\n",
    "                            max_jobs=50,\n",
    "                            strategy_config = StrategyConfig(hyperband_strategy_config=HyperbandStrategyConfig(max_resource=10, min_resource = 1))\n",
    "                           )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to fit the tuner by passing in the S3 paths to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "tuner.fit('S3/path/to/training-data')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This starts up a hyperparameter tuning job. Your work is done, time to sit back and wait for the results!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
